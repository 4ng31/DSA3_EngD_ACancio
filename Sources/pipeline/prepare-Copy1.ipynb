{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-04T14:59:38.510790Z",
     "start_time": "2017-10-04T14:59:38.493504Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bgx/.mega2/Desarrollo/github/radsa/bin\n"
     ]
    }
   ],
   "source": [
    "DIR=%pwd\n",
    "%cd $DIR/radsa/bin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-04T14:59:41.728327Z",
     "start_time": "2017-10-04T14:59:41.694836Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting prepare.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile prepare.py\n",
    "\n",
    "#Input for this software are a configuration file and a survey schedule in csv format.\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "pd.set_option('display.width',512)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "import mmap\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "def find(indexfile,start,end):\n",
    "    dtypes={'start_seconds':np.float64,'start_ttime':'str','freq':np.float64,'filename':'str','start_byte':'int64','end_byte':'int64'}\n",
    "    aa = pd.read_csv(indexfile,dtype=dtypes)\n",
    "    aa.dropna(inplace=True)\n",
    "    aa.set_index('start_seconds',inplace=True,drop=True)\n",
    "    df = aa[(aa.index >= start) & (aa.index <= end)]\n",
    "    return df\n",
    "\n",
    "def sec2time(sec, n_msec=3):\n",
    "    ''' Convert seconds to 'D days, HH:MM:SS.FFF' '''\n",
    "    if hasattr(sec,'__len__'):\n",
    "        return [sec2time(s) for s in sec]\n",
    "    m, s = divmod(sec, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    d, h = divmod(h, 24)\n",
    "    if n_msec > 0:\n",
    "        pattern = '%%02d:%%02d:%%0%d.%df' % (n_msec+3, n_msec)\n",
    "    else:\n",
    "        pattern = r'%02d:%02d:%02d'\n",
    "    if d == 0:\n",
    "        return pattern % (h, m, s)\n",
    "    return ('%d days, ' + pattern) % (d, h, m, s)\n",
    "\n",
    "def time2sec(time, n_msec=3):\n",
    "    ''' Convert 'D days, HH:MM:SS.FFF' to seconds'''\n",
    "    from datetime import datetime as dt\n",
    "    pt=dt.strptime(time,'%H:%M:%S.%f')\n",
    "    total_seconds=pt.second+pt.minute*60+pt.hour*3600\n",
    "    return total_seconds\n",
    "\n",
    "def findposition(Tstart,Tend,filename,first=None,last=None):\n",
    "    print 'Tstart',Tstart\n",
    "    if first and last:\n",
    "        sys.exti(0)\n",
    "        \n",
    "    fsize=os.path.getsize(filename) #size of file (in bytes)  \n",
    "    print 'File:',filename\n",
    "    \n",
    "    if fsize == 0:\n",
    "        print \",,\",filename\n",
    "        sys.exit(1)\n",
    "    \n",
    "    print 'Fsize',fsize\n",
    "    start=0\n",
    "    end=1468\n",
    "    ti=readblocks2(filename,start,end)\n",
    "    print 'Tinicial',ti\n",
    "    \n",
    "    start=fsize-1468\n",
    "    end=fsize\n",
    "    tf=readblocks2(filename,start,end)\n",
    "    print 'Tfinal',tf\n",
    "    \n",
    "    deltaT=(tf[0]-ti[0])/(fsize/1468)\n",
    "    print 'DeltaT',deltaT\n",
    "\n",
    "    if first:\n",
    "        ## start - Tstart\n",
    "        diffT=(tf[0] - Tstart)\n",
    "        print 'DiffT',diffT\n",
    "        nblocks=int(diffT/deltaT)\n",
    "        start=fsize-(nblocks+2)*1468\n",
    "        end=start+1468\n",
    "        \n",
    "        print 'nblocks',nblocks\n",
    "\n",
    "        print 'Fsize',fsize,'start',start,'end',end\n",
    "        tt=readblocks2(filename,start,end)\n",
    "        tt.extend([start,fsize])\n",
    "    \n",
    "    if last:\n",
    "        ## Tend-end\n",
    "        diffT=(Tend-ti[0]) \n",
    "#         print diffT\n",
    "        nblocks=int(diffT/deltaT)\n",
    "        start=nblocks*1468\n",
    "        end=(nblocks+2)*1468\n",
    "        tt=readblocks2(filename,start,end)\n",
    "        tt.extend([0,end])\n",
    "    \n",
    "    #print tt\n",
    "    return tt\n",
    "\n",
    "def filterdata(indexfile,start,end):\n",
    "    \n",
    "    ### Search files corresponding to the valid survey time\n",
    "    start=time2sec(start)\n",
    "    end=time2sec(end)\n",
    "    \n",
    "    df=find(indexfile,start,end)\n",
    "    \n",
    "    if df.empty:\n",
    "        print('DataFrame is empty!')\n",
    "        dtypes={'start_seconds':np.float64,'start_ttime':'str','freq':np.float64,'filename':'str','start_byte':'int64','end_byte':'int64'}\n",
    "        labels=['start_seconds','start_ttime','freq','filename','start_byte','end_byte']\n",
    "        E1=pd.DataFrame(labels,dtypes)\n",
    "        E2=pd.DataFrame(labels,dtypes)\n",
    "        return [E1,E2]\n",
    "    \n",
    "    if len(df.index.values) == 0:\n",
    "        start=start-15\n",
    "        end=end+15\n",
    "        df=find(indexfile,start,end)\n",
    "    \n",
    "    ### Separate the Polarization file list\n",
    "    E1=df[df['filename'].str.contains('_E1_', case=True, flags=0, na=np.nan, regex=True)]\n",
    "    E2=df[df['filename'].str.contains('_E2_', case=True, flags=0, na=np.nan, regex=True)]\n",
    "    \n",
    "    new=[]\n",
    "    ### If there is some seconds in the previous file\n",
    "    \n",
    "    #Check if there are both polarizations\n",
    "    print 'UNTIL HERE OK'\n",
    "    \n",
    "    if E1.index.values[0] > start:\n",
    "        print 'Some seconds in the previous file' \n",
    "        filename=E1.iloc[0]['filename']\n",
    "        numberfile=int(filename.split('_')[-1])-1\n",
    "        if not numberfile == 0:\n",
    "            prevfile='_'.join(filename.split('_')[:-1]+['{0:04}'.format(numberfile)])\n",
    "            new=[findposition(start,end,prevfile,first=True,last=False)]\n",
    "            E1.reset_index(level=0,inplace=True)\n",
    "            result=E1.values.tolist()\n",
    "            del E1\n",
    "            gc.collect()\n",
    "            dtypes={'start_seconds':np.float64,'start_ttime':'str','freq':np.float64,'filename':'str','start_byte':'int64','end_byte':'int64'}\n",
    "            labels=['start_seconds','start_ttime','freq','filename','start_byte','end_byte']\n",
    "            new.extend(result)\n",
    "            E1=pd.DataFrame.from_records(new,columns=labels)\n",
    "            E1.set_index('start_seconds',inplace=True,drop=True)\n",
    "            \n",
    "    new=[]\n",
    "    nextfile=(E1['filename'].tail(1)).values\n",
    "    IX=(E1['filename'].tail(1)).index\n",
    "    new=findposition(start,end,nextfile[0],first=False,last=True)\n",
    "    E1.loc[(E1['filename'].tail(1)).index,  'end_byte'] = new[-1]\n",
    "    print E1\n",
    "     \n",
    "    new=[]\n",
    "    ### If there is some seconds in the previous file  \n",
    "    print E2\n",
    "    if E2.index.values[0] > start:\n",
    "        print 'Some seconds in the previous file' \n",
    "        filename=E2.iloc[0]['filename']\n",
    "        numberfile=int(filename.split('_')[-1])-1\n",
    "        if not numberfile == 0:\n",
    "            prevfile='_'.join(filename.split('_')[:-1]+['{0:04}'.format(numberfile)])\n",
    "            new=[findposition(start,end,prevfile,first=True,last=False)]\n",
    "            E2.reset_index(level=0,inplace=True)\n",
    "            result=E2.values.tolist()\n",
    "            del E2\n",
    "            gc.collect()\n",
    "            dtypes={'start_seconds':np.float64,'start_ttime':'str','freq':np.float64,'filename':'str','start_byte':'int64','end_byte':'int64'}\n",
    "            labels=['start_seconds','start_ttime','freq','filename','start_byte','end_byte']\n",
    "            new.extend(result)\n",
    "            E2=pd.DataFrame.from_records(new,columns=labels)\n",
    "            E2.set_index('start_seconds',inplace=True,drop=True)\n",
    "            \n",
    "    new=[]\n",
    "    nextfile=(E2['filename'].tail(1)).values\n",
    "    IX=(E2['filename'].tail(1)).index\n",
    "    new=findposition(start,end,nextfile[0],first=False,last=True)\n",
    "    E2.loc[(E2['filename'].tail(1)).index,  'end_byte'] = new[-1]\n",
    "    print E2\n",
    "    \n",
    "    return [E1,E2]\n",
    "\n",
    "def readheader(BS,hprint=None):\n",
    "    from bitstring import BitStream\n",
    "    import struct\n",
    "    b = BitStream('0x'+''.join(x.encode('hex') for x in struct.unpack('>72s',BS)))\n",
    "    header = {}\n",
    "    header[\"recordlength\"] = b.read(16).uint   # 16 0..65535\n",
    "    header[\"hdrlen\"] = b.read(8).uint    # 8 0..255\n",
    "    header[\"blocksize\"] = b.read(8).uint   # 8 0..25\n",
    "    header[\"samplerate\"] = b.read(16).uint   # 16 0..65535\n",
    "    header[\"efegain\"] = b.read(10).uint   # 10 0..650\n",
    "    header[\"qu\"] = b.read(3).uint    # 16 0..7 (0=>1bits,1=>2bits,2=>4bits,4=>8bits,5=>16bits, 3,6,7 spare)\n",
    "    header[\"msg\"] = b.read(3).uint    # 3 6\n",
    "    header[\"frameid\"] = b.read(32).uint  # 32 0..4294967295\n",
    "    header[\"version\"] = b.read(7).uint    # 7 0..127\n",
    "    header[\"timetag_samps\"] = b.read(25).uint   # 25 0..17499999\n",
    "    header[\"offsetfreq\"] = b.read(32).int   # 32 0..4294967295\n",
    "    header[\"timetag_secs\"] = b.read(17).uint   # 17 0..86399\n",
    "    header[\"subc\"] = b.read(4).uint    # 4 0..16\n",
    "    header[\"digitalgain\"] = b.read(11).uint   # 11 0..2047\n",
    "    header[\"subchan0_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"subchan1_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"subchan2_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"subchan3_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"sweeprate\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"path_delay\"] = b.read(32).int    # 32 0..2^32-1\n",
    "    header[\"gdspid\"] = b.read(8).uint    # 1 0..1\n",
    "    header[\"hs\"] = b.read(1).uint    # 1 0..1\n",
    "    header[\"semr\"] = b.read(12).int    # 12\n",
    "    header[\"sweepchange\"] = b.read(11).uint   # 11 0..2047\n",
    "    header[\"ncov\"] = b.read(1).uint    # 1 0..1\n",
    "    header[\"ncoreset_c\"] = b.read(11).int    # 11 -1024..+1024\n",
    "    header[\"ncoreset_t\"] = b.read(20).uint   # 20 0..863999\n",
    "    b.read(128).uint    # 128 Empty\n",
    "    \n",
    "    if hprint:\n",
    "        print yaml.dump(header, default_flow_style=False)\n",
    "    \n",
    "    return header\n",
    "\n",
    "def readblocks2(filename,start,end):\n",
    "    with open(filename, 'rb') as f:\n",
    "        fsize=os.path.getsize(filename)\n",
    "        if not fsize == 0:\n",
    "            mm = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)\n",
    "        else:\n",
    "            return ['NaN','NaN','NaN',filename]\n",
    "\n",
    "        mm.seek(start)\n",
    "        position=mm.tell()\n",
    "            \n",
    "        while True:\n",
    "            # Magic Word\n",
    "            byte=mm.read(4)\n",
    "            print byte\n",
    "            if not byte:\n",
    "                break\n",
    "            # Read Header (check cuantization and save timestamp)\n",
    "            header = readheader(mm.read(72),hprint=None)\n",
    "            ## Calculate UTC\n",
    "            X=np.float64(header[\"timetag_samps\"])*np.float64(1./17500000)\n",
    "            Y=np.float64(header[\"path_delay\"])*np.float64(1./35000000)\n",
    "            utctime=np.float64(header[\"timetag_secs\"])+X-Y\n",
    "            ttime=sec2time(utctime,6)\n",
    "            fs=header[\"samplerate\"]\n",
    "#             print utctime,',',ttime,',',filename\n",
    "            mm.read(1392)\n",
    "            if end == mm.tell():\n",
    "                return [utctime,ttime,fs,filename]\n",
    "\n",
    "def readblocks(filename):\n",
    "    import mmap\n",
    "#     print filename   \n",
    "    if filename.split('_')[-1] == '0000':\n",
    "        return []\n",
    "\n",
    "    fsize=os.path.getsize(filename)\n",
    "    if not fsize == 0:\n",
    "        f= open(filename, 'rb')\n",
    "        # memory-map the file, size 0 means whole file\n",
    "        #mm = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)\n",
    "        # memory-map the file, size 0 means whole file\n",
    "        mm = mmap.mmap(f.fileno(), length=1468, offset=0, prot=mmap.PROT_READ)\n",
    "    else:\n",
    "        return ['NaN','NaN','NaN',filename,'0',fsize]\n",
    "    \n",
    "    while True:\n",
    "        # Magic Word\n",
    "        byte=mm.read(4)\n",
    "        if not byte:\n",
    "            break\n",
    "        # Read Header (check cuantization and save timestamp)\n",
    "        header = readheader(mm.read(72),hprint=None)\n",
    "        ## Calculate UTC\n",
    "        X=np.float64(header[\"timetag_samps\"])*np.float64(1./17500000)\n",
    "        Y=np.float64(header[\"path_delay\"])*np.float64(1./35000000)\n",
    "        utctime=np.float64(header[\"timetag_secs\"])+X-Y\n",
    "        ttime=sec2time(utctime,6)\n",
    "        fs=header[\"samplerate\"]\n",
    "        mm.read(1392)\n",
    "        break\n",
    "    f.close()\n",
    "    return [utctime,ttime,fs,filename,int(0),int(fsize)]\n",
    "    \n",
    "    \n",
    "def genindex(indexfile,dirpath):\n",
    "    import csv\n",
    "    print dirpath\n",
    "    \n",
    "    ll=[]\n",
    "    def mycallback(r):\n",
    "        ll.append(r)\n",
    "    \n",
    "    thelist=sorted(glob.glob(dirpath+'/*'))  \n",
    "    pool = mp.Pool(processes=mp.cpu_count())\n",
    "    results = pool.map_async(readblocks, thelist, callback=mycallback)\n",
    "    \n",
    "    with open(indexfile, 'wa') as f:\n",
    "        fieldnames = ['start_seconds','start_ttime','freq','filename','start_byte','end_byte']\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(fieldnames)\n",
    "        writer.writerows(results.get())\n",
    "\n",
    "def main(args):\n",
    "    schedulefile=args.schd\n",
    "    configfile=args.config\n",
    "    workdir=args.workdir\n",
    "    surveypath=args.input\n",
    "    \n",
    "    ## This should be build with enabled IFMS\n",
    "    indexfiles=['ifms1_index.csv','ifms2_index.csv','ifms3_index.csv']\n",
    "\n",
    "    ## Generate First Index for the Survey\n",
    "    for i in indexfiles:\n",
    "        indexfile=workdir+i\n",
    "        try:\n",
    "            os.stat(workdir)\n",
    "        except:\n",
    "            os.mkdir(workdir)\n",
    "        if os.path.isfile(indexfile):\n",
    "            print 'Index OK'\n",
    "        else: \n",
    "            print 'Index file doesn exist.'\n",
    "            print 'Creating...',indexfile\n",
    "            genindex(indexfile,surveypath+i.split('_')[0])\n",
    "            \n",
    "\n",
    "            \n",
    "    ##########################################################################\n",
    "    ## Find UDP valid\n",
    "    headers = ['datetime', 'recordlength', 'source','frec_hz','resolution']\n",
    "    dtypes = {'datetime': 'str', 'recordlength': 'float', 'source': 'str','frec_hz':'float', 'resolution':'int'}\n",
    "    df = pd.read_csv(schedulefile, header=None, names=headers, dtype=dtypes)\n",
    "    for idx in range(0,3,1):\n",
    "        for index, row in df.iterrows():\n",
    "            tstart=datetime.datetime.strptime(row['datetime'],'%Y/%m/%d/%H:%M:%S')\n",
    "            tend=tstart+datetime.timedelta(seconds=row['recordlength'])\n",
    "            \n",
    "            print tstart,tend\n",
    "\n",
    "            E1=filterdata(workdir+indexfiles[idx],tstart.strftime(\"%H:%M:%S.%f\"),tend.strftime(\"%H:%M:%S.%f\"))\n",
    "            E2=filterdata(workdir+indexfiles[idx],tstart.strftime(\"%H:%M:%S.%f\"),tend.strftime(\"%H:%M:%S.%f\"))\n",
    "\n",
    "            \n",
    "    ##########################################################################\n",
    "\n",
    "#     ## Read Schedule\n",
    "#     headers = ['datetime', 'recordlength', 'source','frec_hz','resolution']\n",
    "#     dtypes = {'datetime': 'str', 'recordlength': 'float', 'source': 'str','frec_hz':'float', 'resolution':'int'}\n",
    "#     df = pd.read_csv(schedulefile, header=None, names=headers, dtype=dtypes)\n",
    "    \n",
    "#     ## Generate Data Schedule\n",
    "#     for idx in range(0,3,1):\n",
    "#         for index, row in df.iterrows():\n",
    "            \n",
    "#             tstart=datetime.datetime.strptime(row['datetime'],'%Y/%m/%d/%H:%M:%S')\n",
    "#             tend=tstart+datetime.timedelta(seconds=row['recordlength'])\n",
    "            \n",
    "#             print tstart,tend\n",
    "            \n",
    "#             GDSP1,GDSP2=filterdata(workdir+indexfiles[idx],tstart.strftime(\"%H:%M:%S.%f\"),tend.strftime(\"%H:%M:%S.%f\"))\n",
    "            \n",
    "#             GDSP1.to_csv(workdir+indexfiles[idx]+'gdsp1.csv', mode='a', header=False)\n",
    "#             GDSP2.to_csv(workdir+indexfiles[idx]+'gdsp2.csv', mode='a', header=False)        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    parser = argparse.ArgumentParser(description='Prepare recordered data for reducction.')\n",
    "    parser.add_argument('-s', '--schedule', dest='schd',type=argparse.FileType('r'),\n",
    "                        help='Read schedule file.', required=True)\n",
    "    parser.add_argument('-c', '--config', dest='config',type=argparse.FileType('r'),\n",
    "                        help='Read config file.', required=False)\n",
    "    parser.add_argument('-o', '--workdir', dest='workdir',type=str,\n",
    "                        help='Output directory PATH.', required=True)\n",
    "    parser.add_argument('-i', '--input', dest='input',type=str,\n",
    "                        help='Input directory PATH, Survey PATH.', required=True)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    main(args)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
