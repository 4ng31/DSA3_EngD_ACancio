{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting prepare_par.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile prepare_par.py\n",
    "#Input for this software are a configuration file and a survey schedule in csv format.\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "pd.set_option('display.width',512)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "import mmap\n",
    "import sys\n",
    "import gc\n",
    "from readblock import datareduce\n",
    "\n",
    "def find(indexfile,start,end):\n",
    "    dtypes={'datetime':np.datetime64, 'start_seconds':np.float64,'date':'str','start_ttime':'str','freq':np.float64,'filename':'str','start_byte':'int64','end_byte':'int64'}\n",
    "#     aa = pd.read_csv(indexfile,dtype=dtypes)\n",
    "    aa = pd.read_csv(indexfile,parse_dates={'datetime':['date','start_ttime']},\n",
    "                     keep_date_col = True, \n",
    "                     index_col='datetime',dtype=dtypes)  \n",
    "    columns = ['start_seconds','date','start_ttime','freq','start_byte','end_byte']\n",
    "    aa.drop(columns, inplace=True, axis=1)\n",
    "    aa.dropna(inplace=True)\n",
    "#     aa.set_index('start_seconds',inplace=True,drop=True)    \n",
    "#     df = aa[(aa.start_seconds >= start) & (aa.start_seconds <= end)]\n",
    "    df = aa[(aa.index >= start) & (aa.index <= end)]\n",
    "    return df\n",
    "\n",
    "def sec2time(sec, n_msec=3):\n",
    "    ''' Convert seconds to 'D days, HH:MM:SS.FFF' '''\n",
    "    if hasattr(sec,'__len__'):\n",
    "        return [sec2time(s) for s in sec]\n",
    "    m, s = divmod(sec, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    d, h = divmod(h, 24)\n",
    "    if n_msec > 0:\n",
    "        pattern = '%%02d:%%02d:%%0%d.%df' % (n_msec+3, n_msec)\n",
    "    else:\n",
    "        pattern = r'%02d:%02d:%02d'\n",
    "    if d == 0:\n",
    "        return pattern % (h, m, s)\n",
    "    return ('%d days, ' + pattern) % (d, h, m, s)\n",
    "\n",
    "def time2sec(time, n_msec=3):\n",
    "    ''' Convert 'D days, HH:MM:SS.FFF' to seconds'''\n",
    "    from datetime import datetime as dt\n",
    "    pt=dt.strptime(time,'%H:%M:%S.%f')\n",
    "    total_seconds=pt.second+pt.minute*60+pt.hour*3600\n",
    "    return total_seconds\n",
    "\n",
    "\n",
    "def equals(DF,DF1):\n",
    "    try:\n",
    "        pd.assert_frame_equal(DF, DF1)\n",
    "        return True\n",
    "    except:  # appeantly AssertionError doesn't catch all\n",
    "        return False\n",
    "        \n",
    "\n",
    "def findUDP(indexfile,start,end):\n",
    "    \n",
    "    ### Search files corresponding to the valid survey time\n",
    "    start=np.datetime64(start)\n",
    "    end=np.datetime64(end)\n",
    "   \n",
    "    df=find(indexfile,start,end)\n",
    "       \n",
    "    if df.empty:\n",
    "        dtypes={'datetime':np.datetime64,'filename':'str'}\n",
    "        labels=['datetime','filename']\n",
    "        E1=pd.DataFrame(np.nan,labels,dtypes)\n",
    "        E2=pd.DataFrame(np.nan,labels,dtypes)\n",
    "        return [E1,E2]\n",
    "    \n",
    "    A=False\n",
    "    B=False\n",
    "    newstart=start\n",
    "    newend=end\n",
    "    \n",
    "    delta = np.timedelta64(1,'m')\n",
    "\n",
    "    while 1:\n",
    "        df1=df   \n",
    "        \n",
    "        if (df.index.values)[0] > start:\n",
    "            newstart=start-delta\n",
    "        else:\n",
    "            A=True\n",
    "            \n",
    "        if (df.index.values)[-1]+delta < end:\n",
    "            newend=end+delta \n",
    "        else:\n",
    "            B=True\n",
    "            \n",
    "        if A&B:\n",
    "            break    \n",
    "            \n",
    "        df=find(indexfile,newstart,newend)\n",
    "        \n",
    "        if equals(df,df1):\n",
    "            break\n",
    "\n",
    "    ### Separate the Polarization file list\n",
    "    E1=df[df['filename'].str.contains('_E1_', case=True, flags=0, na=np.nan, regex=True)]\n",
    "    E2=df[df['filename'].str.contains('_E2_', case=True, flags=0, na=np.nan, regex=True)]\n",
    "    \n",
    "    return [E1,E2]\n",
    "\n",
    "def readheader(BS,hprint=None):\n",
    "    \"\"\"Reads the header of a UNIX format raw data file.\n",
    "    Notes\n",
    "    =====\n",
    "    @param BS : byte stream\n",
    "    \"\"\"\n",
    "    \n",
    "    from bitstruct import unpack\n",
    "    \n",
    "    header={}\n",
    "    header[\"magic\"],header[\"recordlength\"],header[\"hdrlen\"],header[\"blocksize\"],\\\n",
    "    header[\"samplerate\"],header[\"cfegain\"],header[\"qu\"],header[\"msg\"],\\\n",
    "    header[\"frameid\"],header[\"version\"],header[\"timetag_samps\"],header[\"offsetfreq\"],\\\n",
    "    header[\"timetag_secs\"],header[\"subc\"],header[\"digitalgain\"],header[\"subchan0_offset\"],\\\n",
    "    header[\"subchan1_offset\"],header[\"subchan2_offset\"],header[\"subchan3_offset\"],\\\n",
    "    header[\"sweeprate\"],header[\"path_delay\"],header[\"gdspid\"],header[\"hs\"],\\\n",
    "    header[\"semr\"],header[\"sweepchange\"],header[\"ncov\"],header[\"ncoreset_c\"],\\\n",
    "    header[\"ncoreset_t\"],empty = unpack('>r32u16u8u8u16u10u3u3u32u7u25s32u17u4u11s32s32s32s32s32s32u8u1s12u11u1s11u20r128', BS)\n",
    "                  \n",
    "    if hprint:\n",
    "        import yaml\n",
    "        print(yaml.dump(header, default_flow_style=False))\n",
    "        \n",
    "    return header\n",
    "\n",
    "# def readblocks2(filename,start,end):\n",
    "#     with open(filename, 'rb') as f:\n",
    "#         fsize=os.path.getsize(filename)\n",
    "#         if not fsize == 0:\n",
    "#             mm = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)\n",
    "#         else:\n",
    "#             return ['NaN','NaN','NaN',filename]\n",
    "\n",
    "#         mm.seek(start)\n",
    "#         position=mm.tell()\n",
    "            \n",
    "#         while True:\n",
    "#             # Magic Word\n",
    "#             byte=mm.read(4)\n",
    "#             print byte\n",
    "#             if not byte:\n",
    "#                 break\n",
    "#             # Read Header (check cuantization and save timestamp)\n",
    "#             header = readheader(mm.read(72),hprint=None)\n",
    "#             ## Calculate UTC\n",
    "#             X=np.float64(header[\"timetag_samps\"])*np.float64(1./17500000)\n",
    "#             Y=np.float64(header[\"path_delay\"])*np.float64(1./35000000)\n",
    "#             utctime=np.float64(header[\"timetag_secs\"])+X-Y\n",
    "#             ttime=sec2time(utctime,6)\n",
    "#             fs=header[\"samplerate\"]\n",
    "# #             print utctime,',',ttime,',',filename\n",
    "#             mm.read(1392)\n",
    "#             if end == mm.tell():\n",
    "#                 return [utctime,ttime,fs,filename]\n",
    "\n",
    "def readblocks(filename):\n",
    "    import mmap\n",
    "#     print filename   \n",
    "    if filename.split('_')[-1] == '0000':\n",
    "        return []\n",
    "\n",
    "    fsize=os.path.getsize(filename)\n",
    "    if not fsize == 0:\n",
    "        f= open(filename, 'rb')\n",
    "        # memory-map the file, size 0 means whole file\n",
    "        mm = mmap.mmap(f.fileno(), length=1468, offset=0, prot=mmap.PROT_READ)\n",
    "    else:\n",
    "        return ['NaN','NaN','NaN',filename,'0',fsize]\n",
    "    \n",
    "    while True:\n",
    "        # Read Header (check cuantization and save timestamp)\n",
    "        header = readheader(mm.read(76),hprint=None)\n",
    "        ## Calculate UTC\n",
    "        X=np.float64(header[\"timetag_samps\"])*np.float64(1./17500000)\n",
    "        Y=np.float64(header[\"path_delay\"])*np.float64(1./35000000)\n",
    "        utctime=np.float64(header[\"timetag_secs\"])+X-Y\n",
    "        ttime=sec2time(utctime,6)\n",
    "        fs=header[\"samplerate\"]\n",
    "        mm.read(1392)\n",
    "        break\n",
    "    f.close()\n",
    "    \n",
    "    ## Generate DATE by YAR, DOY and TIME\n",
    "    aux=filename.split('/')[-1]\n",
    "    aux=aux.split('_')\n",
    "    year=int(aux[2])\n",
    "    doy=int(aux[3])\n",
    "    starttime=int(aux[6])\n",
    "    datetimestring= \"%d %d %d\" % (year, doy, starttime)\n",
    "    a=datetime.datetime.strptime(datetimestring, '%Y %j %H%M%S')\n",
    "\n",
    "    datetimestring= \"%d %d %s\" % (year, doy, ttime)\n",
    "    b=datetime.datetime.strptime(datetimestring, '%Y %j %H:%M:%S.%f')\n",
    "    if a.strftime('%F%H%M%S') > b.strftime('%F%H%M%S'):\n",
    "        doy=doy+1\n",
    "   \n",
    "    datetimestring= \"%d %d %s\" % (year, doy, ttime)\n",
    "    c=datetime.datetime.strptime(datetimestring, '%Y %j %H:%M:%S.%f')\n",
    "    ddate=c.strftime('%F')\n",
    "    \n",
    "    return [utctime,ddate,ttime,fs,filename,int(0),int(fsize)]\n",
    "    \n",
    "def genindex(indexfile,dirpath):\n",
    "    import csv\n",
    "    print dirpath\n",
    "        \n",
    "    ll=sorted(glob.glob(dirpath+'/*'))  \n",
    "    pp = mp.Pool(6)\n",
    "    results = pp.map(readblocks, ll, chunksize=1)\n",
    "    pp.close()\n",
    "    pp.join()\n",
    "        \n",
    "    with open(indexfile, 'wa') as f:\n",
    "        fieldnames = ['start_seconds','date','start_ttime','freq','filename','start_byte','end_byte']\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(fieldnames)\n",
    "        writer.writerows(results)\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def applyParallel(dfGrouped, schedule, workdir, func):\n",
    "    p = Pool(cpu_count() - 1)\n",
    "    rest_list = p.map(func, [(group, schedule.iloc[[((group['scan']).values)[0]]], workdir) for name, group in dfGrouped])\n",
    "#    rest_list = p.map(func, [group for name, group in dfGrouped])\n",
    "    p.close()\n",
    "    p.join()\n",
    "    return 0\n",
    "    \n",
    "def apply_reduce(args): \n",
    "    reduced=args[0]\n",
    "    schd=args[1]\n",
    "    workdir=args[2]\n",
    "    print schd\n",
    "    print reduced\n",
    "    if not reduced.empty:\n",
    "        filelist = reduced['filename'].tolist()\n",
    "        filetimes = reduced.index.to_pydatetime().tolist()\n",
    "        schdstart=datetime.datetime.strptime((schd.datetime.values)[0],'%Y/%m/%d/%H:%M:%S')\n",
    "        schdend=schdstart+datetime.timedelta(seconds=(schd.recordlength.values)[0])\n",
    "        schdtimes = [schdstart, schdend ]\n",
    "        scannumber=((reduced['scan']).values)[0]\n",
    "        datareduce(schdtimes,filelist,filetimes,scannumber,workdir)\n",
    "    return 0\n",
    "        \n",
    "\n",
    "def main(args):\n",
    "    schedulefile=args.schd\n",
    "    configfile=args.config\n",
    "    workdir=args.workdir\n",
    "    surveypath=args.input\n",
    "    \n",
    "    ## This should be build with enabled IFMS\n",
    "    indexfiles=['ifms1_index.csv','ifms2_index.csv','ifms3_index.csv']\n",
    "\n",
    "    ## Generate First Index for the Survey\n",
    "    for i in indexfiles:\n",
    "        indexfile=workdir+i\n",
    "        try:\n",
    "            os.stat(workdir)\n",
    "        except:\n",
    "            os.mkdir(workdir)\n",
    "        if os.path.isfile(indexfile):\n",
    "            print 'Index OK'\n",
    "        else: \n",
    "            print 'Index file doesn exist.'\n",
    "            print 'Creating...',indexfile\n",
    "            genindex(indexfile,surveypath+i.split('_')[0])\n",
    "            \n",
    "    ##########################################################################\n",
    "    ## Find valid UDP\n",
    "    headers = ['datetime', 'recordlength', 'source','frec_hz','resolution']\n",
    "    dtypes = {'datetime': 'str', 'recordlength': 'float', 'source': 'str','frec_hz':'float', 'resolution':'int'}\n",
    "    schd = pd.read_csv(schedulefile, header=None, names=headers, dtype=dtypes)\n",
    "    \n",
    "    \n",
    "    ## Generate Data Schedule\n",
    "    for idx in range(0,2,1):\n",
    "        j=0\n",
    "        Flag1=True\n",
    "        Flag2=True\n",
    "        for index, row in schd.iterrows():\n",
    "            path=workdir+indexfiles[idx]\n",
    "             \n",
    "            tstart=datetime.datetime.strptime(row['datetime'],'%Y/%m/%d/%H:%M:%S')\n",
    "            tend=tstart+datetime.timedelta(seconds=row['recordlength'])\n",
    "            \n",
    "            E1,E2=findUDP(path,tstart.strftime(\"%Y-%m-%d %H:%M:%S.%f\"),tend.strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "            E1.dropna(inplace=True)\n",
    "            E2.dropna(inplace=True)\n",
    "            if not E1.empty and not (E1.index.values[0] == 'datetime'):\n",
    "                E1['SCAN']=j\n",
    "                if not ( os.path.isfile(path+'gdsp1.csv') and Flag1):\n",
    "                    E1.to_csv(path+'gdsp1.csv', mode='a', header=False)\n",
    "                    Flag1=False\n",
    "                \n",
    "            if not E2.empty and not (E2.index.values[0] == 'datetime'):\n",
    "                E2['SCAN']=j\n",
    "                if not ( os.path.isfile(path+'gdsp2.csv') and Flag2):\n",
    "                    E2.to_csv(path+'gdsp2.csv', mode='a', header=False)\n",
    "                    Flag2=False\n",
    "            j=j+1\n",
    "\n",
    "    ##########################################################################\n",
    "    ## Reduce\n",
    "    \n",
    "    ## Read SCHD File\n",
    "    #df\n",
    "    \n",
    "    ## Read Index File\n",
    "    for idx in range(0,2,1):\n",
    "        for gdsp in ['gdsp1.csv','gdsp2.csv']:\n",
    "            filetoread=path+gdsp\n",
    "            if os.path.isfile(filetoread):\n",
    "\n",
    "                headers = ['timestamp','filename','scan']\n",
    "                aa = pd.read_csv(filetoread,\n",
    "                                 header=None,\n",
    "                                 names = headers,\n",
    "                                 parse_dates={'datetime':['timestamp']},\n",
    "                                 #keep_date_col = True, \n",
    "                                 index_col='datetime'\n",
    "                                )\n",
    "\n",
    "                grouped = aa.groupby('scan')\n",
    "                applyParallel(grouped, schd, workdir, apply_reduce)\n",
    "                \n",
    "            else:    \n",
    "                print('Missing polarization')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    parser = argparse.ArgumentParser(description='Prepare recordered data for reducction.')\n",
    "    parser.add_argument('-s', '--schedule', dest='schd',type=argparse.FileType('r'),\n",
    "                        help='Read schedule file.', required=True)\n",
    "    parser.add_argument('-c', '--config', dest='config',type=argparse.FileType('r'),\n",
    "                        help='Read config file.', required=False)\n",
    "    parser.add_argument('-o', '--workdir', dest='workdir',type=str,\n",
    "                        help='Output directory PATH.', required=True)\n",
    "    parser.add_argument('-i', '--input', dest='input',type=str,\n",
    "                        help='Input directory PATH, Survey PATH.', required=True)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    main(args)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
