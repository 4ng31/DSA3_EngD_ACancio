{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-05T20:11:43.828996",
     "start_time": "2016-06-05T20:11:43.815899"
    },
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile genindex.py\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import struct\n",
    "import mmap\n",
    "import sys\n",
    "import yaml\n",
    "import argparse\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from bitstring import BitStream, ConstBitStream,Bits\n",
    "from bitarray import bitarray as BitArray\n",
    "from itertools import chain\n",
    "import csv\n",
    "\n",
    "def sec2time(sec, n_msec=3):\n",
    "    ''' Convert seconds to 'D days, HH:MM:SS.FFF' '''\n",
    "    if hasattr(sec,'__len__'):\n",
    "        return [sec2time(s) for s in sec]\n",
    "    m, s = divmod(sec, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    d, h = divmod(h, 24)\n",
    "    if n_msec > 0:\n",
    "        pattern = '%%02d:%%02d:%%0%d.%df' % (n_msec+3, n_msec)\n",
    "    else:\n",
    "        pattern = r'%02d:%02d:%02d'\n",
    "    if d == 0:\n",
    "        return pattern % (h, m, s)\n",
    "    return ('%d days, ' + pattern) % (d, h, m, s)\n",
    "\n",
    "def readheader(BS,hprint=None):\n",
    "    b = BitStream('0x'+''.join(x.encode('hex') for x in struct.unpack('>72s',BS)))\n",
    "    #magic = b.read(32).hex# 32 magic word\n",
    "    header = {}\n",
    "    header[\"recordlength\"] = b.read(16).uint   # 16 0..65535\n",
    "    header[\"hdrlen\"] = b.read(8).uint    # 8 0..255\n",
    "    header[\"blocksize\"] = b.read(8).uint   # 8 0..25\n",
    "    header[\"samplerate\"] = b.read(16).uint   # 16 0..65535\n",
    "    header[\"efegain\"] = b.read(10).uint   # 10 0..650\n",
    "    header[\"qu\"] = b.read(3).uint    # 16 0..7 (0=>1bits,1=>2bits,2=>4bits,4=>8bits,5=>16bits, 3,6,7 spare)\n",
    "    header[\"msg\"] = b.read(3).uint    # 3 6\n",
    "    header[\"frameid\"] = b.read(32).uint  # 32 0..4294967295\n",
    "    header[\"version\"] = b.read(7).uint    # 7 0..127\n",
    "    header[\"timetag_samps\"] = b.read(25).uint   # 25 0..17499999\n",
    "    header[\"offsetfreq\"] = b.read(32).int   # 32 0..4294967295\n",
    "    header[\"timetag_secs\"] = b.read(17).uint   # 17 0..86399\n",
    "    header[\"subc\"] = b.read(4).uint    # 4 0..16\n",
    "    header[\"digitalgain\"] = b.read(11).uint   # 11 0..2047\n",
    "    header[\"subchan0_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"subchan1_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"subchan2_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"subchan3_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"sweeprate\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"path_delay\"] = b.read(32).int    # 32 0..2^32-1\n",
    "    header[\"gdspid\"] = b.read(8).uint    # 1 0..1\n",
    "    header[\"hs\"] = b.read(1).uint    # 1 0..1\n",
    "    header[\"semr\"] = b.read(12).int    # 12\n",
    "    header[\"sweepchange\"] = b.read(11).uint   # 11 0..2047\n",
    "    header[\"ncov\"] = b.read(1).uint    # 1 0..1\n",
    "    header[\"ncoreset_c\"] = b.read(11).int    # 11 -1024..+1024\n",
    "    header[\"ncoreset_t\"] = b.read(20).uint   # 20 0..863999\n",
    "    b.read(128).uint    # 128 Empty\n",
    "    \n",
    "    if hprint:\n",
    "        #print header\n",
    "        print yaml.dump(header, default_flow_style=False)\n",
    "    \n",
    "    return header\n",
    "\n",
    "def readblocks(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        fsize=os.path.getsize(filename)\n",
    "        # memory-map the file, size 0 means whole file\n",
    "        mm = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)\n",
    "\n",
    "        while True:\n",
    "            # Magic Word\n",
    "            byte=mm.read(4)\n",
    "            if not byte:\n",
    "                break\n",
    "            # Read Header (check cuantization and save timestamp)\n",
    "            header = readheader(mm.read(72),hprint=None)\n",
    "            ## Calculate UTC\n",
    "            utctime=np.float64(header[\"timetag_secs\"])+np.float64(header[\"timetag_samps\"])*np.float64(1./17500000)-np.float64(header[\"path_delay\"])*np.float64(1./35000000)\n",
    "            sr=header[\"samplerate\"]\n",
    "            ttime=sec2time(utctime,6)\n",
    "            print format(utctime, '.10f'),header[\"timetag_secs\"],header[\"timetag_samps\"],header[\"path_delay\"],',',ttime,',',sr,',',filename,',','0',',',fsize\n",
    "            mm.read(1392)\n",
    "            break\n",
    "        \n",
    "        while True:\n",
    "            # Magic Word\n",
    "            byte=mm.read(4)\n",
    "            if not byte:\n",
    "                break\n",
    "            # Read Header (check cuantization and save timestamp)\n",
    "            header = readheader(mm.read(72),hprint=None)\n",
    "            ## Calculate UTC\n",
    "            utctime=np.float64(header[\"timetag_secs\"])+np.float64(header[\"timetag_samps\"])*np.float64(1./17500000)-np.float64(header[\"path_delay\"])*np.float64(1./35000000)\n",
    "            sr=header[\"samplerate\"]\n",
    "            ttime=sec2time(utctime,6)\n",
    "            print format(utctime, '.10f'),header[\"timetag_secs\"],header[\"timetag_samps\"],header[\"path_delay\"],',',ttime,',',sr,',',filename,',','0',',',fsize\n",
    "            mm.read(1392)\n",
    "            break\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "def main(argus):    \n",
    "    filename=argus.inputfile  #your filename goes here.\n",
    "\n",
    "    output=argus.outputpath\n",
    "    fsize=os.path.getsize(filename) #size of file (in bytes)  \n",
    "    if fsize == 0:\n",
    "        print \",,\",filename\n",
    "        sys.exit(1)\n",
    "#     print filename, fsize\n",
    "    head, tail = os.path.split(filename)\n",
    "    start='12:10:00'\n",
    "    end='12:10:55'\n",
    "    readblocks(filename)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    ## CMD arguments\n",
    "    arguments=sys.argv[1:]\n",
    " \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-i', '--inputfile', default='False')\n",
    "    parser.add_argument('-o', '--outputpath', default='False')\n",
    "    #parser.add_argument('-n', '--nblocks', default='None')\n",
    "    \n",
    "    argus = parser.parse_args(arguments)\n",
    "#     print \"Starting...\"\n",
    "    main(argus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-06T15:51:34.589564",
     "start_time": "2016-06-06T15:51:34.574903"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile searchvaliddata.py\n",
    "import pandas as pd\n",
    "pd.set_option('display.width',256)\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def find(indexfile,start,end):\n",
    "\n",
    "    aa = pd.read_csv(indexfile)\n",
    "    print aa\n",
    "    \n",
    "    df = aa[(aa['start_seconds'] >= start) & (aa['start_seconds'] <= end)]\n",
    "    print df\n",
    "    return df\n",
    "\n",
    "def sec2time(sec, n_msec=3):\n",
    "    ''' Convert seconds to 'D days, HH:MM:SS.FFF' '''\n",
    "    if hasattr(sec,'__len__'):\n",
    "        return [sec2time(s) for s in sec]\n",
    "    m, s = divmod(sec, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    d, h = divmod(h, 24)\n",
    "    if n_msec > 0:\n",
    "        pattern = '%%02d:%%02d:%%0%d.%df' % (n_msec+3, n_msec)\n",
    "    else:\n",
    "        pattern = r'%02d:%02d:%02d'\n",
    "    if d == 0:\n",
    "        return pattern % (h, m, s)\n",
    "    return ('%d days, ' + pattern) % (d, h, m, s)\n",
    "\n",
    "def time2sec(time, n_msec=3):\n",
    "    ''' Convert 'D days, HH:MM:SS.FFF' to seconds'''\n",
    "    from datetime import datetime as dt\n",
    "    pt =dt.strptime(time,'%H:%M:%S.%f')\n",
    "    total_seconds=pt.second+pt.minute*60+pt.hour*3600\n",
    "    return total_seconds\n",
    "\n",
    "def filterdata(indexfile,start,end):\n",
    "    ### Search files corresponding to the valid survey time\n",
    "    start=time2sec(start)\n",
    "    end=time2sec(end)\n",
    "    \n",
    "    df=find(indexfile,start,end)\n",
    "    \n",
    "    ### Separate the Polarization file list\n",
    "    \n",
    "    E1=df[df['file'].str.contains('_E1_', case=True, flags=0, na=np.nan, regex=True)]\n",
    "    E2=df[df['file'].str.contains('_E2_', case=True, flags=0, na=np.nan, regex=True)]\n",
    "    \n",
    "    print E1.head(1)\n",
    "    print E1.tail(1)\n",
    "    \n",
    "    print E2.head(1)\n",
    "    print E2.tail(1)\n",
    "    \n",
    "    ### If there is some seconds in the previous file \n",
    "    \n",
    "    if E1.iloc[0]['file'] > start:\n",
    "        filename=E1.iloc[0]['file']\n",
    "        numberfile=int(filename.split('_')[-1])-1\n",
    "        if not numberfile == 0:\n",
    "            print '_'.join(filename.split('_')[:-1]+['{0:04}'.format(numberfile)])\n",
    "        else:\n",
    "            \"First survey file\"\n",
    "    \n",
    "    if E1.iloc[0]['file'] > start:\n",
    "        filename=E2.iloc[0]['file']\n",
    "        numberfile=int(filename.split('_')[-1])-1\n",
    "        if not numberfile == 0:\n",
    "            print '_'.join(filename.split('_')[:-1]+['{0:04}'.format(numberfile)])\n",
    "        else:\n",
    "            \"First survey file\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-06T15:51:40.007002",
     "start_time": "2016-06-06T15:51:38.872821"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import struct\n",
    "import mmap\n",
    "import sys\n",
    "import yaml\n",
    "import argparse\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from bitstring import BitStream, ConstBitStream,Bits\n",
    "from bitarray import bitarray as BitArray\n",
    "from itertools import chain\n",
    "import csv\n",
    "\n",
    "def sec2time(sec, n_msec=3):\n",
    "    ''' Convert seconds to 'D days, HH:MM:SS.FFF' '''\n",
    "    if hasattr(sec,'__len__'):\n",
    "        return [sec2time(s) for s in sec]\n",
    "    m, s = divmod(sec, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    d, h = divmod(h, 24)\n",
    "    if n_msec > 0:\n",
    "        pattern = '%%02d:%%02d:%%0%d.%df' % (n_msec+3, n_msec)\n",
    "    else:\n",
    "        pattern = r'%02d:%02d:%02d'\n",
    "    if d == 0:\n",
    "        return pattern % (h, m, s)\n",
    "    return ('%d days, ' + pattern) % (d, h, m, s)\n",
    "\n",
    "def time2sec(time, n_msec=3):\n",
    "    ''' Convert 'D days, HH:MM:SS.FFF' to seconds'''\n",
    "    from datetime import datetime as dt\n",
    "    pt =dt.strptime(time,'%H:%M:%S.%f')\n",
    "    total_seconds=pt.second+pt.minute*60+pt.hour*3600\n",
    "    return total_seconds\n",
    "\n",
    "def readheader(BS,hprint=None):\n",
    "    b = BitStream('0x'+''.join(x.encode('hex') for x in struct.unpack('>72s',BS)))\n",
    "    #magic = b.read(32).hex# 32 magic word\n",
    "    header = {}\n",
    "    header[\"recordlength\"] = b.read(16).uint   # 16 0..65535\n",
    "    header[\"hdrlen\"] = b.read(8).uint    # 8 0..255\n",
    "    header[\"blocksize\"] = b.read(8).uint   # 8 0..25\n",
    "    header[\"samplerate\"] = b.read(16).uint   # 16 0..65535\n",
    "    header[\"efegain\"] = b.read(10).uint   # 10 0..650\n",
    "    header[\"qu\"] = b.read(3).uint    # 16 0..7 (0=>1bits,1=>2bits,2=>4bits,4=>8bits,5=>16bits, 3,6,7 spare)\n",
    "    header[\"msg\"] = b.read(3).uint    # 3 6\n",
    "    header[\"frameid\"] = b.read(32).uint  # 32 0..4294967295\n",
    "    header[\"version\"] = b.read(7).uint    # 7 0..127\n",
    "    header[\"timetag_samps\"] = b.read(25).uint   # 25 0..17499999\n",
    "    header[\"offsetfreq\"] = b.read(32).int   # 32 0..4294967295\n",
    "    header[\"timetag_secs\"] = b.read(17).uint   # 17 0..86399\n",
    "    header[\"subc\"] = b.read(4).uint    # 4 0..16\n",
    "    header[\"digitalgain\"] = b.read(11).uint   # 11 0..2047\n",
    "    header[\"subchan0_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"subchan1_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"subchan2_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"subchan3_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"sweeprate\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"path_delay\"] = b.read(32).int    # 32 0..2^32-1\n",
    "    header[\"gdspid\"] = b.read(8).uint    # 1 0..1\n",
    "    header[\"hs\"] = b.read(1).uint    # 1 0..1\n",
    "    header[\"semr\"] = b.read(12).int    # 12\n",
    "    header[\"sweepchange\"] = b.read(11).uint   # 11 0..2047\n",
    "    header[\"ncov\"] = b.read(1).uint    # 1 0..1\n",
    "    header[\"ncoreset_c\"] = b.read(11).int    # 11 -1024..+1024\n",
    "    header[\"ncoreset_t\"] = b.read(20).uint   # 20 0..863999\n",
    "    b.read(128).uint    # 128 Empty\n",
    "    \n",
    "    if hprint:\n",
    "        #print header\n",
    "        print yaml.dump(header, default_flow_style=False)\n",
    "    \n",
    "    return header\n",
    "\n",
    "def readblocks(filename,start,end):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # memory-map the file, size 0 means whole file\n",
    "        mm = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)\n",
    "\n",
    "        mm.seek(start)\n",
    "        position=mm.tell()\n",
    "        print position\n",
    "            \n",
    "        while True:\n",
    "            # Magic Word\n",
    "            byte=mm.read(4)\n",
    "            if not byte:\n",
    "                break\n",
    "            # Read Header (check cuantization and save timestamp)\n",
    "            header = readheader(mm.read(72),hprint=None)\n",
    "            ## Calculate UTC\n",
    "            X=np.float64(header[\"timetag_samps\"])*np.float64(1./17500000)\n",
    "            Y=np.float64(header[\"path_delay\"])*np.float64(1./35000000)\n",
    "            utctime=np.float64(header[\"timetag_secs\"])+X-Y\n",
    "            ttime=sec2time(utctime,6)\n",
    "            print utctime,',',ttime,',',filename\n",
    "            mm.read(1392)\n",
    "            if end == mm.tell():\n",
    "                return [utctime,ttime,filename]\n",
    "            \n",
    "def findposition(Tstart,Tend,filename,first=None,last=None):\n",
    "    \n",
    "    if first and last:\n",
    "        sys.exti(0)\n",
    "        \n",
    "    fsize=os.path.getsize(filename) #size of file (in bytes)  \n",
    "    \n",
    "    if fsize == 0:\n",
    "        print \",,\",filename\n",
    "        sys.exit(1)\n",
    "    \n",
    "    print fsize\n",
    "    start=0\n",
    "    end=1468\n",
    "    ti=readblocks(filename,start,end)\n",
    "    print ti\n",
    "    \n",
    "    start=fsize-1468\n",
    "    end=fsize\n",
    "    tf=readblocks(filename,start,end)\n",
    "    print tf\n",
    "    \n",
    "    deltaT=(tf[0]-ti[0])/(fsize/1468)\n",
    "    print deltaT\n",
    "\n",
    "    if first:\n",
    "        ## start - Tstart\n",
    "        diffT=(tf[0] - Tstart)\n",
    "        print diffT\n",
    "        nblocks=int(diffT/deltaT)\n",
    "        start=fsize-(nblocks+2)*1468\n",
    "        end=start+1468\n",
    "        tt=readblocks(filename,start,end)\n",
    "        tt.extend([start,])\n",
    "    \n",
    "    if last:\n",
    "        ## Tend-end\n",
    "        diffT=(Tend-ti[0]) \n",
    "        print diffT\n",
    "        nblocks=int(diffT/deltaT)\n",
    "        start=nblocks*1468\n",
    "        end=(nblocks+2)*1468\n",
    "        tt=readblocks(filename,start,end)\n",
    "        tt.extend([0,end])\n",
    "    \n",
    "    print tt\n",
    "        \n",
    "\n",
    "first=True\n",
    "last=None\n",
    "if first:\n",
    "    filename='/media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1_122807_0002'\n",
    "#     filename='/media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1_195710_0003'\n",
    "    \n",
    "if last:\n",
    "    filename='/media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1_122807_0003'\n",
    "#     filename='/media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1_195710_0004'\n",
    "\n",
    "start='12:30:00.0'\n",
    "end='12:30:55.0'\n",
    "\n",
    "start=time2sec(start)\n",
    "end=time2sec(end)\n",
    "findposition(start,end,filename,first,last)\n",
    "\n",
    "first=None\n",
    "last=True\n",
    "if first:\n",
    "    filename='/media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1_122807_0002'\n",
    "#     filename='/media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1_195710_0003'\n",
    "    \n",
    "if last:\n",
    "    filename='/media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1_122807_0003'\n",
    "#     filename='/media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1_195710_0004'\n",
    "\n",
    "start='12:30:00.0'\n",
    "end='12:30:55.0'\n",
    "\n",
    "start=time2sec(start)\n",
    "end=time2sec(end)\n",
    "findposition(start,end,filename,first,last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-07T19:06:33.705564",
     "start_time": "2016-06-07T19:06:33.694280"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting prepare.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile prepare.py\n",
    "\n",
    "#Input for this software are a configuration file and a survey schedule in csv format.\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "pd.set_option('display.width',256)\n",
    "import numpy as np\n",
    "import datetime\n",
    "import mmap\n",
    "import sys\n",
    "\n",
    "def find(indexfile,start,end):\n",
    "    print indexfile,start,end\n",
    "\n",
    "    aa = pd.read_csv(indexfile)\n",
    "    \n",
    "    #print aa.head()\n",
    "    \n",
    "    df = aa[(aa.index >= start) & (aa.index <= end)]\n",
    "\n",
    "    #print df.head()\n",
    "    return df\n",
    "\n",
    "def sec2time(sec, n_msec=3):\n",
    "    ''' Convert seconds to 'D days, HH:MM:SS.FFF' '''\n",
    "    if hasattr(sec,'__len__'):\n",
    "        return [sec2time(s) for s in sec]\n",
    "    m, s = divmod(sec, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    d, h = divmod(h, 24)\n",
    "    if n_msec > 0:\n",
    "        pattern = '%%02d:%%02d:%%0%d.%df' % (n_msec+3, n_msec)\n",
    "    else:\n",
    "        pattern = r'%02d:%02d:%02d'\n",
    "    if d == 0:\n",
    "        return pattern % (h, m, s)\n",
    "    return ('%d days, ' + pattern) % (d, h, m, s)\n",
    "\n",
    "def time2sec(time, n_msec=3):\n",
    "    ''' Convert 'D days, HH:MM:SS.FFF' to seconds'''\n",
    "    from datetime import datetime as dt\n",
    "    pt=dt.strptime(time,'%H:%M:%S.%f')\n",
    "    total_seconds=pt.second+pt.minute*60+pt.hour*3600\n",
    "    return total_seconds\n",
    "\n",
    "def findposition(Tstart,Tend,filename,first=None,last=None):\n",
    "    \n",
    "    if first and last:\n",
    "        sys.exti(0)\n",
    "        \n",
    "    fsize=os.path.getsize(filename) #size of file (in bytes)  \n",
    "    \n",
    "    if fsize == 0:\n",
    "        print \",,\",filename\n",
    "        sys.exit(1)\n",
    "    \n",
    "#     print fsize\n",
    "    start=0\n",
    "    end=1468\n",
    "    ti=readblocks2(filename,start,end)\n",
    "#     print ti\n",
    "    \n",
    "    start=fsize-1468\n",
    "    end=fsize\n",
    "    tf=readblocks2(filename,start,end)\n",
    "#     print tf\n",
    "    \n",
    "    deltaT=(tf[0]-ti[0])/(fsize/1468)\n",
    "#     print deltaT\n",
    "\n",
    "    if first:\n",
    "        ## start - Tstart\n",
    "        diffT=(tf[0] - Tstart)\n",
    "#         print diffT\n",
    "        nblocks=int(diffT/deltaT)\n",
    "        start=fsize-(nblocks+2)*1468\n",
    "        end=start+1468\n",
    "        tt=readblocks2(filename,start,end)\n",
    "#         tt.extend([start,])\n",
    "    \n",
    "    if last:\n",
    "        ## Tend-end\n",
    "        diffT=(Tend-ti[0]) \n",
    "#         print diffT\n",
    "        nblocks=int(diffT/deltaT)\n",
    "        start=nblocks*1468\n",
    "        end=(nblocks+2)*1468\n",
    "        tt=readblocks2(filename,start,end)\n",
    "#         tt.extend([0,end])\n",
    "    \n",
    "    #print tt\n",
    "    return tt\n",
    "\n",
    "def filterdata(indexfile,start,end):\n",
    "    ### Search files corresponding to the valid survey time\n",
    "    start=time2sec(start)\n",
    "    end=time2sec(end)\n",
    "    \n",
    "    df=find(indexfile,start,end)\n",
    "    \n",
    "    ### Separate the Polarization file list\n",
    "    \n",
    "    E1=df[df['filename'].str.contains('_E1_', case=True, flags=0, na=np.nan, regex=True)]\n",
    "    E2=df[df['filename'].str.contains('_E2_', case=True, flags=0, na=np.nan, regex=True)]\n",
    "        \n",
    "    E1.reset_index(level=0, inplace=True)   \n",
    "    E2.reset_index(level=0, inplace=True)\n",
    "    \n",
    "    if len(E1.index) == 1:\n",
    "        print 'One file'\n",
    "    else:\n",
    "        \n",
    "        new=[]\n",
    "        ### If there is some seconds in the previous file  \n",
    "        if E1.iloc[0]['index'] > start:\n",
    "            print 'Some seconds in the previous file' \n",
    "            filename=E1.iloc[0]['filename']\n",
    "            numberfile=int(filename.split('_')[-1])-1\n",
    "        \n",
    "            if not numberfile == 0:\n",
    "                prevfile='_'.join(filename.split('_')[:-1]+['{0:04}'.format(numberfile)])\n",
    "                new=[findposition(start,end,prevfile,first=True,last=False)]\n",
    "                result=E1.values.tolist()\n",
    "                new.extend(result)\n",
    "            else:\n",
    "                print \"First survey file\"\n",
    "                \n",
    "        print new\n",
    "        \n",
    "        new=[]       \n",
    "        if E1.iloc[-1]['index'] < end:\n",
    "            print 'Some seconds before end of file' \n",
    "            filename=E1.iloc[0]['filename']\n",
    "            new=[findposition(start,end,filename,first=False,last=True)]\n",
    "            result=E1.values.tolist()\n",
    "            new.extend(result)\n",
    "            print new\n",
    "            \n",
    "        new=[]\n",
    "        ### If there is some seconds in the previous file  \n",
    "        if E2.iloc[0]['index'] > start:\n",
    "            print 'Some seconds in the previous file' \n",
    "            filename=E2.iloc[0]['filename']\n",
    "            numberfile=int(filename.split('_')[-1])-1\n",
    "\n",
    "        if not numberfile == 0:\n",
    "            prevfile='_'.join(filename.split('_')[:-1]+['{0:04}'.format(numberfile)])\n",
    "            new=[findposition(start,end,prevfile,first=True,last=False)]\n",
    "            result=E2.values.tolist()\n",
    "            new.extend(result)\n",
    "        else:\n",
    "            print \"First survey file\"\n",
    "        \n",
    "        print new\n",
    "        \n",
    "        new=[]\n",
    "        if E1.iloc[-1]['index']  < end:\n",
    "            print 'Some seconds before end of file' \n",
    "            filename=E2.iloc[0]['filename']\n",
    "            new=[findposition(start,end,filename,first=False,last=True)]\n",
    "            result=E2.values.tolist()\n",
    "            new.extend(result)\n",
    "\n",
    "        print new\n",
    "\n",
    "def readheader(BS,hprint=None):\n",
    "    from bitstring import BitStream\n",
    "    import struct\n",
    "    b = BitStream('0x'+''.join(x.encode('hex') for x in struct.unpack('>72s',BS)))\n",
    "    #magic = b.read(32).hex# 32 magic word\n",
    "    header = {}\n",
    "    header[\"recordlength\"] = b.read(16).uint   # 16 0..65535\n",
    "    header[\"hdrlen\"] = b.read(8).uint    # 8 0..255\n",
    "    header[\"blocksize\"] = b.read(8).uint   # 8 0..25\n",
    "    header[\"samplerate\"] = b.read(16).uint   # 16 0..65535\n",
    "    header[\"efegain\"] = b.read(10).uint   # 10 0..650\n",
    "    header[\"qu\"] = b.read(3).uint    # 16 0..7 (0=>1bits,1=>2bits,2=>4bits,4=>8bits,5=>16bits, 3,6,7 spare)\n",
    "    header[\"msg\"] = b.read(3).uint    # 3 6\n",
    "    header[\"frameid\"] = b.read(32).uint  # 32 0..4294967295\n",
    "    header[\"version\"] = b.read(7).uint    # 7 0..127\n",
    "    header[\"timetag_samps\"] = b.read(25).uint   # 25 0..17499999\n",
    "    header[\"offsetfreq\"] = b.read(32).int   # 32 0..4294967295\n",
    "    header[\"timetag_secs\"] = b.read(17).uint   # 17 0..86399\n",
    "    header[\"subc\"] = b.read(4).uint    # 4 0..16\n",
    "    header[\"digitalgain\"] = b.read(11).uint   # 11 0..2047\n",
    "    header[\"subchan0_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"subchan1_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"subchan2_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"subchan3_offset\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"sweeprate\"] = b.read(32).int    # 32 -2147483647..+2147483647\n",
    "    header[\"path_delay\"] = b.read(32).int    # 32 0..2^32-1\n",
    "    header[\"gdspid\"] = b.read(8).uint    # 1 0..1\n",
    "    header[\"hs\"] = b.read(1).uint    # 1 0..1\n",
    "    header[\"semr\"] = b.read(12).int    # 12\n",
    "    header[\"sweepchange\"] = b.read(11).uint   # 11 0..2047\n",
    "    header[\"ncov\"] = b.read(1).uint    # 1 0..1\n",
    "    header[\"ncoreset_c\"] = b.read(11).int    # 11 -1024..+1024\n",
    "    header[\"ncoreset_t\"] = b.read(20).uint   # 20 0..863999\n",
    "    b.read(128).uint    # 128 Empty\n",
    "    \n",
    "    if hprint:\n",
    "        #print header\n",
    "        print yaml.dump(header, default_flow_style=False)\n",
    "    \n",
    "    return header\n",
    "\n",
    "def readblocks2(filename,start,end):\n",
    "    with open(filename, 'rb') as f:\n",
    "        fsize=os.path.getsize(filename)\n",
    "        if not fsize == 0:\n",
    "            # memory-map the file, size 0 means whole file\n",
    "            mm = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)\n",
    "        else:\n",
    "            return ['nan','nan','nan',filename,'0',int(fsize)]\n",
    "\n",
    "        mm.seek(start)\n",
    "        position=mm.tell()\n",
    "#         print position\n",
    "            \n",
    "        while True:\n",
    "            # Magic Word\n",
    "            byte=mm.read(4)\n",
    "            if not byte:\n",
    "                break\n",
    "            # Read Header (check cuantization and save timestamp)\n",
    "            header = readheader(mm.read(72),hprint=None)\n",
    "            ## Calculate UTC\n",
    "            X=np.float64(header[\"timetag_samps\"])*np.float64(1./17500000)\n",
    "            Y=np.float64(header[\"path_delay\"])*np.float64(1./35000000)\n",
    "            utctime=np.float64(header[\"timetag_secs\"])+X-Y\n",
    "            ttime=sec2time(utctime,6)\n",
    "            fs=header[\"samplerate\"]\n",
    "#             print utctime,',',ttime,',',filename\n",
    "            mm.read(1392)\n",
    "            if end == mm.tell():\n",
    "                return [utctime,ttime,fs,filename,int(start),int(end)]\n",
    "\n",
    "def readblocks(filename):\n",
    "    import mmap\n",
    "\n",
    "    with open(filename, 'rb') as f:\n",
    "        fsize=os.path.getsize(filename)\n",
    "        if not fsize == 0:\n",
    "            # memory-map the file, size 0 means whole file\n",
    "            mm = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)\n",
    "        else:\n",
    "            return ['nan','nan','nan',filename,'0',fsize]\n",
    "\n",
    "        while True:\n",
    "            # Magic Word\n",
    "            byte=mm.read(4)\n",
    "            if not byte:\n",
    "                break\n",
    "            # Read Header (check cuantization and save timestamp)\n",
    "            header = readheader(mm.read(72),hprint=None)\n",
    "            ## Calculate UTC\n",
    "            X=np.float64(header[\"timetag_samps\"])*np.float64(1./17500000)\n",
    "            Y=np.float64(header[\"path_delay\"])*np.float64(1./35000000)\n",
    "            utctime=np.float64(header[\"timetag_secs\"])+X-Y\n",
    "            ttime=sec2time(utctime,6)\n",
    "            fs=header[\"samplerate\"]\n",
    "            mm.read(1392)\n",
    "            return [utctime,ttime,fs,filename,int(0),int(fsize)]\n",
    "            break\n",
    "\n",
    "def genindex(indexfile,workdir):\n",
    "    import csv\n",
    "    thelist=glob.glob(workdir+'/*') \n",
    "    ll=[]\n",
    "    for i in thelist:\n",
    "        if i.split('_')[-1] == '0000':\n",
    "            continue\n",
    "        line=readblocks(i)\n",
    "        ll.append(line)\n",
    "    with open(indexfile, 'wa') as f:\n",
    "        fieldnames = ['start_seconds','start_ttime','freq','filename','start_byte','end_byte']\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(fieldnames)\n",
    "        writer.writerows(ll)\n",
    "\n",
    "## Variable \n",
    "\n",
    "### Schedule from the Observing Report\n",
    "schedulefile='/home/bgx/MEGAsync-Work/ITeDA/DSA3/Proyectos/detection/software/schedule.csv'\n",
    "configfile='/home/bgx/MEGAsync-Work/ITeDA/DSA3/Proyectos/detection/software/prepare.conf'\n",
    "dataschedulefile='/home/bgx/MEGAsync-Work/ITeDA/DSA3/Proyectos/detection/software/dataschedule.csv'\n",
    "workdir='/home/bgx/MEGAsync-Work/ITeDA/DSA3/Proyectos/detection/software/'\n",
    "\n",
    "surveypath='/media/bgx/CONAE/'\n",
    "\n",
    "indexfiles=['ESU1_index.csv','ESU2_index.csv','ESU3_index.csv']\n",
    "\n",
    "## Generate First Index for the Survey\n",
    "for i in indexfiles:\n",
    "    indexfile=workdir+i\n",
    "    print indexfile\n",
    "    if os.path.isfile(indexfile):\n",
    "        print 'Index OK'\n",
    "    else: \n",
    "        print 'Index file doesn exist.'\n",
    "        print 'Creating...',indexfile\n",
    "        genindex(indexfile,surveypath+i.split('_')[0])\n",
    "\n",
    "## Read Schedule\n",
    "headers = ['datetime', 'recordlength', 'source','frec_hz','resolution']\n",
    "dtypes = {'datetime': 'str', 'recordlength': 'float', 'source': 'str','frec_hz':'float', 'resolution':'int'}\n",
    "df = pd.read_csv(schedulefile, header=None, names=headers, dtype=dtypes)\n",
    "#print df\n",
    "\n",
    "## Generate Data Schedule\n",
    "a=0\n",
    "for index, row in df.iterrows():\n",
    "    #print row\n",
    "    tstart=datetime.datetime.strptime(row['datetime'],'%Y/%m/%d/%H:%M:%S')\n",
    "    tend=tstart+datetime.timedelta(seconds=row['recordlength'])\n",
    "#     print tstart.timetuple().tm_yday, tstart.strftime(\"%H:%M:%S.%f\"),tend.strftime(\"%H:%M:%S.%f\")\n",
    "    filterdata(workdir+indexfiles[0],tstart.strftime(\"%H:%M:%S.%f\"),tend.strftime(\"%H:%M:%S.%f\"))\n",
    "    if a == 2:\n",
    "        break\n",
    "    a=a+1\n",
    "\n",
    "## Should be a list of sources to process\n",
    "# source=['0521']\n",
    "# selected=df[df['source'].str.contains(source[0], case=True, flags=0, na=np.nan, regex=True)]\n",
    "# print selected\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-07T10:56:52.407024",
     "start_time": "2016-06-07T10:56:52.364462"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bgx/MEGAsync-Work/ITeDA/DSA3/Proyectos/detection/software/ESU1_index.csv\n",
      "Index OK\n",
      "/home/bgx/MEGAsync-Work/ITeDA/DSA3/Proyectos/detection/software/ESU2_index.csv\n",
      "Index OK\n",
      "/home/bgx/MEGAsync-Work/ITeDA/DSA3/Proyectos/detection/software/ESU3_index.csv\n",
      "Index OK\n",
      "datetime        2016/03/28/12:10:00\n",
      "recordlength                     56\n",
      "source                     1934-638\n",
      "frec_hz                      100000\n",
      "resolution                       16\n",
      "Name: 0, dtype: object\n",
      "88 12:10:00.000000 12:10:56.000000\n",
      "/home/bgx/MEGAsync-Work/ITeDA/DSA3/Proyectos/detection/software/ESU1_index.csv 43800 43856\n",
      "                start_seconds start_ttime  \\\n",
      "43803.903055  12:10:03.903055         176   \n",
      "43860.989691  12:11:00.989691         176   \n",
      "43920.980357  12:12:00.980357         176   \n",
      "43980.966648  12:13:00.966648         176   \n",
      "44040.961689  12:14:00.961689         176   \n",
      "\n",
      "                                                       filename  start_byte  \\\n",
      "43803.903055  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1...           0   \n",
      "43860.989691  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1...           0   \n",
      "43920.980357  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1...           0   \n",
      "43980.966648  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1...           0   \n",
      "44040.961689  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1...           0   \n",
      "\n",
      "               end_byte  \n",
      "43803.903055   95778192  \n",
      "43860.989691  100650484  \n",
      "43920.980357  100643144  \n",
      "43980.966648  100657824  \n",
      "44040.961689  100720948  \n",
      "                start_seconds start_ttime  \\\n",
      "43803.903055  12:10:03.903055         176   \n",
      "43803.902532  12:10:03.902532         176   \n",
      "\n",
      "                                                       filename  start_byte  \\\n",
      "43803.903055  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1...           0   \n",
      "43803.902532  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E2...           0   \n",
      "\n",
      "              end_byte  \n",
      "43803.903055  95778192  \n",
      "43803.902532  95794340  \n",
      "                start_seconds start_ttime  \\\n",
      "43803.903055  12:10:03.903055         176   \n",
      "\n",
      "                                                       filename  start_byte  \\\n",
      "43803.903055  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1...           0   \n",
      "\n",
      "              end_byte  \n",
      "43803.903055  95778192  \n",
      "                start_seconds start_ttime  \\\n",
      "43803.903055  12:10:03.903055         176   \n",
      "\n",
      "                                                       filename  start_byte  \\\n",
      "43803.903055  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1...           0   \n",
      "\n",
      "              end_byte  \n",
      "43803.903055  95778192  \n",
      "                start_seconds start_ttime  \\\n",
      "43803.902532  12:10:03.902532         176   \n",
      "\n",
      "                                                       filename  start_byte  \\\n",
      "43803.902532  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E2...           0   \n",
      "\n",
      "              end_byte  \n",
      "43803.902532  95794340  \n",
      "                start_seconds start_ttime  \\\n",
      "43803.902532  12:10:03.902532         176   \n",
      "\n",
      "                                                       filename  start_byte  \\\n",
      "43803.902532  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E2...           0   \n",
      "\n",
      "              end_byte  \n",
      "43803.902532  95794340  \n"
     ]
    }
   ],
   "source": [
    "%run prepare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-07T10:55:11.556389",
     "start_time": "2016-06-07T10:55:11.518245"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                start_seconds start_ttime  \\\n",
      "43803.903055  12:10:03.903055         176   \n",
      "43860.989691  12:11:00.989691         176   \n",
      "43920.980357  12:12:00.980357         176   \n",
      "43980.966648  12:13:00.966648         176   \n",
      "44040.961689  12:14:00.961689         176   \n",
      "\n",
      "                                                       filename  start_byte  \\\n",
      "43803.903055  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1...           0   \n",
      "43860.989691  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1...           0   \n",
      "43920.980357  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1...           0   \n",
      "43980.966648  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1...           0   \n",
      "44040.961689  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1...           0   \n",
      "\n",
      "               end_byte  \n",
      "43803.903055   95778192  \n",
      "43860.989691  100650484  \n",
      "43920.980357  100643144  \n",
      "43980.966648  100657824  \n",
      "44040.961689  100720948  \n",
      "                start_seconds start_ttime  \\\n",
      "43803.903055  12:10:03.903055         176   \n",
      "43803.902532  12:10:03.902532         176   \n",
      "\n",
      "                                                       filename  start_byte  \\\n",
      "43803.903055  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E1...           0   \n",
      "43803.902532  /media/bgx/CONAE/ESU1/MG11_NET4_2016_088_DD_E2...           0   \n",
      "\n",
      "              end_byte  \n",
      "43803.903055  95778192  \n",
      "43803.902532  95794340  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "indexfile='/home/bgx/MEGAsync-Work/ITeDA/DSA3/Proyectos/detection/software/ESU1_index.csv'\n",
    "start=43800\n",
    "end=43856\n",
    "\n",
    "aa = pd.read_csv(indexfile)\n",
    "    \n",
    "print aa.head()\n",
    "\n",
    "df = aa[(aa.index >= start) & (aa.index <= end)]\n",
    "print df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-07T14:40:14.354435",
     "start_time": "2016-06-07T14:40:14.326601"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  1.1  1.1  1.1\n",
      "     0    1    2\n",
      "0  1.1  1.1  1.1\n",
      "1  2.2  2.2  2.2\n"
     ]
    }
   ],
   "source": [
    "# Add a row to df  \n",
    "from pandas import DataFrame as df  \n",
    "import numpy as np  \n",
    "mydf = df([1.1, 1.1, 1.1]).T\n",
    "print mydf\n",
    "arow2 = [2.2, 2.2, 2.2]  \n",
    "mynparray = mydf.values\n",
    "mynparray = np.vstack((mynparray,arow2))  \n",
    "mydf = df(mynparray)\n",
    "print mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
